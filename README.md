Our project explores the potential of integrating self-attention mechanisms into neural network models for image recognition on CIFAR-10 dataset, focusing on two distinct types: pairwise and patchwise self-attention. 

We develop a neural network model that leverages self-attention that significantly improves model performance to achieve higher accuracy in image recognition tasks, while also being less computationally demanding compared to a baseline model(SAN -10). 

